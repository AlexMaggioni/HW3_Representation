{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k_bJg7BWDBT"
      },
      "source": [
        "# Objectif :\n",
        "\n",
        "Dans ce devoir, vous implémenterez l'algorithme d'apprentissage contrastif auto-supervisé, [SimCLR](https://arxiv.org/abs/2002.05709), en utilisant PyTorch. Vous utiliserez le dataset STL-10 pour ce devoir.\n",
        "\n",
        "Vous devez compléter la définition de la classe `Net`, la définition de la classe de dataset `SimCLRDataset` et la perte SimCLR dans la classe `Trainer`. Vous devez exécuter la boucle d'entraînement, sauvegarder le meilleur modèle d'entraînement et évaluer en utilisant la tâche de classification `sonde linéaire`. Comme nous n'avons pas assez de ressources GPU et que l'algorithme d'apprentissage contrastif comme SimCLR a généralement besoin d'environ `1000` époques pour s'entraîner (nous n'avons que `70` époques), vous n'obtiendrez peut-être pas les meilleures performances. Ainsi, du côté des performances, tant que vous voyez que la perte diminue (jusqu'à environ 7.4 à `70` époques) et que la précision augmente, c'est bon.\n",
        "\n",
        "Note :\n",
        "\n",
        "- **Remplir la définition de la classe Net (5 points).**\n",
        "- **Remplir la définition de la classe de dataset SimCLRDataset (10 points).**\n",
        "- **Remplir la perte SimCLR dans la classe Trainer (20 points).**\n",
        "- **Enregistrer la perte d'entraînement dans les 70 époques, plus elle est basse, mieux c'est (5 points).**\n",
        "- **Enregistrer la précision de la sonde linéaire, plus elle est haute, mieux c'est (5 points).**\n",
        "- **Rédiger un rapport incluant :**\n",
        "  - **Comment vous sélectionnez l'augmentation des données (transformation) dans le pool de transformations.**\n",
        "  - **Comment vous implémentez la perte SimCLR et expliquez pourquoi votre perte SimCLR est efficace en termes de calcul et équivalente à la fonction de perte dans l'article.**\n",
        "  - **Inclure la courbe de perte d'entraînement et la précision en aval (15 points). Notez que la logique de journalisation n'est pas fournie, veuillez l'implémenter avant de commencer l'entraînement.**\n",
        "---\n",
        "Veuillez NE PAS changer la configuration fournie. Ne changez le code donné que si vous êtes sûr que le changement est nécessaire. Il est recommandé d'**utiliser une session CPU pour déboguer** lorsque le GPU n'est pas nécessaire puisque Colab ne donne que 12 heures d'accès GPU gratuit à la fois. Si vous utilisez toutes les ressources GPU, vous pouvez envisager d'utiliser les ressources GPU de Kaggle. Merci et bonne chance !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TSjaMEiemQe"
      },
      "source": [
        "# Apprentissage auto-supervisé : SimCLR\n",
        "\n",
        "Apprentissage auto-supervisé\n",
        "\n",
        "1.   Concevoir une tâche auxiliaire.\n",
        "2.   Entraîner le réseau de base sur la tâche auxiliaire.\n",
        "3.   Évaluer sur la tâche aval : Entraîner un nouveau décodeur basé sur l'encodeur formé.\n",
        "\n",
        "Plus spécifiquement, comme l'un des algorithmes d'apprentissage auto-supervisé les plus réussis, SimCLR, un algorithme d'apprentissage contrastif, est notre centre d'intérêt aujourd'hui. Ci-dessous, nous allons mettre en œuvre SimCLR comme un exemple d'apprentissage auto-supervisé."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ocq-13HDLET"
      },
      "source": [
        "<img src=\"https://camo.githubusercontent.com/35af3432fbe91c56a934b5ee58931b4848ab35043830c9dd6f08fa41e6eadbe7/68747470733a2f2f312e62702e626c6f6773706f742e636f6d2f2d2d764834504b704539596f2f586f3461324259657276492f414141414141414146704d2f766146447750584f79416f6b4143385868383532447a4f67457332324e68625877434c63424741735948512f73313630302f696d616765342e676966\" width=\"650\" height=\"650\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MtZk2Wb_V7Z7"
      },
      "outputs": [],
      "source": [
        "# Config\n",
        "# Comme nous utilisons jupyter notebook, nous utilisons easydict pour micic argparse. N'hésitez pas à utiliser d'autres formats de configuration\n",
        "from easydict import EasyDict\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "config = {\n",
        "    'dataset_name': 'stl10',\n",
        "    'workers': 1,\n",
        "    'epochs': 70,\n",
        "    'batch_size': 3072,\n",
        "    'lr': 0.0003,\n",
        "    'weight_decay': 1e-4,\n",
        "    'seed': 4242,\n",
        "    'fp16_precision': True,\n",
        "    'out_dim': 128,\n",
        "    'temperature': 0.5,\n",
        "    'n_views': 2,\n",
        "    'device': \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "}\n",
        "args = EasyDict(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6fxqKRifbgC"
      },
      "source": [
        "Nous allons utiliser le [dataset STL-10](https://cs.stanford.edu/~acoates/stl10/).\n",
        "\n",
        "Aperçu\n",
        "\n",
        "*   10 classes : avion, oiseau, voiture, chat, cerf, chien, cheval, singe, bateau, camion.\n",
        "*   Les images sont en couleur et mesurent **96x96** pixels.\n",
        "*   500 images d'entraînement (10 plis pré-définis), 800 images de test par classe.\n",
        "*   100000 images non étiquetées pour l'apprentissage non supervisé. Ces exemples sont extraits d'une distribution d'images similaire mais plus large. Par exemple, elle contient d'autres types d'animaux (ours, lapins, etc.) et de véhicules (trains, bus, etc.) en plus de ceux du set étiqueté.\n",
        "*   Les images ont été acquises à partir d'exemples étiquetés sur ImageNet.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D9x3PGGlwQO"
      },
      "source": [
        "## Préparation\n",
        "\n",
        "Définir un ResNet-18 et une couche MLP supplémentaire comme le modèle d'entraînement dans la tâche auxiliaire."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hNUQ1b8lp68n"
      },
      "outputs": [],
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.basemodel = models.resnet18(pretrained=False, num_classes=args.out_dim)\n",
        "        self.fc_in_features = self.basemodel.fc.in_features\n",
        "        self.backup_fc = None\n",
        "\n",
        "        # On ajoute la `projection head g(.)` après le average pooling. \n",
        "        # Voici un extrait du papier SimCLR: \n",
        "        #  \"We use a MLP with one hidden layer to obtain zi = g(hi) = W(2)σ(W(1)hi) where σ is a ReLU nonlinearity. Here hi ∈ Rd is the output after the average pooling layer.\"\n",
        "        self.basemodel.fc = nn.Sequential(\n",
        "            nn.Linear(self.fc_in_features, self.fc_in_features),\n",
        "            nn.ReLU(),\n",
        "            self.basemodel.fc\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.basemodel(x)\n",
        "\n",
        "    def linear_probe(self):\n",
        "        self.freeze_basemodel_encoder()\n",
        "        self.backup_fc = self.basemodel.fc  # Sauvegarde de la dernière couche linéaire\n",
        "        # ToDo: implement la sonde linéaire pour votre tâche en aval. Un prob linéaire est simplement une couche linéaire (pas de MLP, pas de couche d'activation incluse) après le codeur appris.\n",
        "        self.basemodel.fc = nn.Linear(self.fc_in_features, 10)\n",
        "\n",
        "    def restore_backbone(self):\n",
        "        self.basemodel.fc = self.backup_fc\n",
        "        self.backup_fc = None\n",
        "\n",
        "    def freeze_basemodel_encoder(self):\n",
        "        # ne pas geler les poids self.basemodel.fc\n",
        "        for name, param in self.basemodel.named_parameters():\n",
        "            if 'fc' not in name:\n",
        "                param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKxWA4tDg9vE"
      },
      "source": [
        "# Étape 1 : Concevoir la tâche auxiliaire."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Construire le dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bg61k4QVfa2_"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "\n",
        "#############################################################################\n",
        "# Calcul des valeurs de la moyenne et de l'écart-type pour la normalisation #\n",
        "#############################################################################\n",
        "\n",
        "# # Define a transform to convert images to tensors\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.ToTensor()\n",
        "# ])\n",
        "# \n",
        "# # Load the STL-10 dataset with the defined transform\n",
        "# dataset = datasets.STL10(root='./datasets', split='unlabeled', download=True, transform=transform)\n",
        "# \n",
        "# # Create a DataLoader\n",
        "# dataloader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
        "# \n",
        "# def compute_mean_std(loader):\n",
        "#     channel_sum, channel_squared_sum, num_batches = 0, 0, 0\n",
        "#     for data, _ in loader:\n",
        "#         # Rearrange batch to be the shape of [B, C, H, W]\n",
        "#         data = data.view(data.size(0), data.size(1), -1)\n",
        "#         # Update sums and squared sums\n",
        "#         channel_sum += torch.mean(data, dim=[0, 2])\n",
        "#         channel_squared_sum += torch.mean(data**2, dim=[0, 2])\n",
        "#         num_batches += 1\n",
        "#     mean = channel_sum / num_batches\n",
        "#     std = (channel_squared_sum / num_batches - mean ** 2) ** 0.5\n",
        "#     return mean, std\n",
        "# \n",
        "# # Compute and print mean and std\n",
        "# mean, std = compute_mean_std(dataloader)\n",
        "# print(\"\\n\")\n",
        "# print(f\"Mean: {mean.tolist()}\")\n",
        "# print(f\"Std: {std.tolist()}\")\n",
        "\n",
        "#############################################################################\n",
        "# Classes pour le chargement des données et les transformations pour SimCLR #\n",
        "#############################################################################\n",
        "\n",
        "class View_sampler(object):\n",
        "    \"\"\"This class randomly sample two transforms from the list of transforms for the SimCLR to use. It is used in the SimCLRDataset.get_dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, transforms, n_views=2):\n",
        "        self.transforms = transforms\n",
        "        self.n_views = n_views\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return [self.transforms(x) for i in range(self.n_views)]\n",
        "\n",
        "\n",
        "class SimCLRDataset:\n",
        "    def __init__(self, root_folder=\"./datasets\"):\n",
        "        self.root_folder = root_folder\n",
        "\n",
        "    @staticmethod\n",
        "    def transforms_pool(size=96):\n",
        "\n",
        "        stochasticGaussianBlur = transforms.Compose([\n",
        "            transforms.GaussianBlur(11, sigma=(0.1, 2.0)),  \n",
        "        ])\n",
        "\n",
        "        data_transforms = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(size=(size, size)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomApply([transforms.ColorJitter(0.8, 0.8, 0.8, 0.2)], p=0.8),\n",
        "            transforms.RandomGrayscale(p=0.2), \n",
        "            transforms.RandomApply([transforms.GaussianBlur(11, sigma=(0.1, 2.0))], p=0.5),\n",
        "            transforms.ToTensor(), \n",
        "            transforms.Normalize(mean=[0.44058355689048767, 0.42731037735939026, 0.38579756021499634], std=[0.2686561346054077, 0.2612513303756714, 0.2684949040412903]) # Ces valeurs ont été calculées précédemment\n",
        "        ])\n",
        "        \n",
        "        return data_transforms\n",
        "\n",
        "    def get_dataset(self):\n",
        "        dataset_fn = lambda: datasets.STL10(self.root_folder, split='unlabeled', transform=View_sampler(self.transforms_pool(), 2), download=True)\n",
        "        return dataset_fn()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTHLDeCalsbx"
      },
      "source": [
        "## Définir le chargeur de données, l'optimiseur et le planificateur\n",
        "\n",
        "Qu'est-ce qu'un planificateur ?\n",
        "\n",
        "Un planificateur aide à optimiser la convergence, à éviter les minima locaux et potentiellement à améliorer la performance du modèle sur la tâche donnée. Le taux d'apprentissage est l'un des hyperparamètres les plus importants pour l'entraînement des réseaux neuronaux, et trouver un programme de taux d'apprentissage approprié peut être crucial pour le succès de votre modèle.\n",
        "\n",
        "En savoir plus ici : https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CpMp8XB3lma1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "model = Net()\n",
        "dataset = SimCLRDataset()\n",
        "train_dataset = dataset.get_dataset()\n",
        "\n",
        "# ToDo, définir un chargeur de données basé sur le train_dataset avec drop_last=True\n",
        "dataloader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.workers, drop_last=True)\n",
        "\n",
        "# ToDo, définir un optimiseur avec args.lr comme taux d'apprentissage et args.weight_decay comme weight_decay\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay) # Utilisé AdamW car il y a une utilisation de weight_decay. On aurait aussi pu utiliser LARS comme dans le papier.\n",
        "\n",
        "# ToDo, définir un planificateur lr_scheduler CosineAnnealingLR pour l'optimiseur\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(dataloader), eta_min=0, last_epoch=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBeD23fj0UdR"
      },
      "source": [
        "# Définir le formateur"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrEbwApkCnVc"
      },
      "source": [
        "L'Automatic Mixed Precision (AMP) est une technique visant à améliorer la vitesse et l'efficacité de l'entraînement des réseaux neuronaux profonds en utilisant l'entraînement en précision mixte.\n",
        "\n",
        "**Introduction à l'AMP**\n",
        "\n",
        "L'AMP permet à l'entraînement des réseaux neuronaux d'utiliser simultanément l'arithmétique à simple précision (FP32) et à demi-précision (FP16). L'idée principale derrière l'AMP est de réaliser certaines opérations en FP16 pour exploiter l'arithmétique plus rapide et la réduction de l'utilisation de la mémoire de calcul à précision inférieure, tout en maintenant les parties critiques du calcul en FP32 pour assurer la précision et la stabilité du modèle.\n",
        "\n",
        "**Pourquoi Nous Ne Pouvons Pas Toujours Utiliser le FP16**\n",
        "\n",
        "\n",
        "\n",
        "*   **Stabilité Numérique** : Le FP16 a une plage dynamique plus petite et une précision inférieure par rapport au FP32. Cette limitation peut conduire à une instabilité numérique, telle que des sous-débordements et des surdébordements, en particulier pendant des opérations qui impliquent de petites valeurs de gradient ou nécessitent une haute précision numérique. Cela peut affecter négativement la convergence et la précision du modèle entraîné.\n",
        "*   **Exigences Sélectives de Précision** : Certaines opérations et couches au sein des réseaux neuronaux sont plus sensibles à la précision que d'autres. Par exemple, les mises à jour de poids dans les optimiseurs peuvent nécessiter le FP32 pour maintenir la précision dans le temps. Les stratégies AMP impliquent donc d'appliquer sélectivement le FP16 à des parties du calcul où cela peut être bénéfique sans compromettre l'ensemble du processus d'entraînement.\n",
        "\n",
        "Ci-dessous, nous présentons comment inclure la logique AMP dans la procédure d'entraînement standard de torch.\n",
        "\n",
        "Avant d'inclure AMP :\n",
        "```python\n",
        "for batch in data_loader:\n",
        "    # Forward pass\n",
        "    inputs, targets = batch\n",
        "    outputs = model(inputs)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    # Backward pass and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "```\n",
        "\n",
        "Après avoir inclus AMP :\n",
        "```python\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "scaler = GradScaler()\n",
        "\n",
        "for batch in data_loader:\n",
        "    inputs, targets = batch[0].cuda(), batch[1].cuda()\n",
        "\n",
        "    # Forward pass\n",
        "    with autocast():\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "    # Backward pass and optimize\n",
        "    optimizer.zero_grad()\n",
        "    scaler.scale(loss).backward()\n",
        "    scaler.step(optimizer)\n",
        "    scaler.update()\n",
        "```\n",
        "\n",
        "\n",
        "Read more here: https://pytorch.org/docs/stable/amp.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBOPRrzsemQi"
      },
      "source": [
        "## Implémenter la fonction de perte dans l'entraîneur\n",
        "L'algorithme de la fonction de perte SimCLR est le suivant :\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "&\\text{for all } i \\in \\{1, \\ldots, 2N\\} \\text{ and } j \\in \\{1, \\ldots, 2N\\} \\text{ do} \\\\\n",
        "&\\quad s_{i,j} = \\frac{z_i^\\top z_j}{\\|z_i\\|\\|z_j\\|} \\quad \\text{pairwise similarity} \\\\\n",
        "&\\text{end for} \\\\\n",
        "&\\text{define } \\ell(i,j) \\text{ as } \\ell(i,j) = -\\log \\left( \\frac{\\exp(s_{i,j} / \\tau)}{\\sum_{k=1}^{2N} \\mathbb{1}_{[k \\neq j]} \\exp(s_{i,k} / \\tau)} \\right) \\\\\n",
        "&\\mathcal{L} = \\frac{1}{2N} \\sum_{k=1}^{N} \\left[\\ell(2k-1, 2k) + \\ell(2k, 2k-1)\\right] \\\\\n",
        "&\\text{update networks } f \\text{ and } g \\text{ to minimize } \\mathcal{L}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "\n",
        "Veuillez remplir les blancs de la fonction de perte ci-dessous. Conseil : mettez en place un masque pour éviter d'inclure la similarité entre soi et soi, ainsi que les paires positives et les paires négatives."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qo_7-Eop0T4Y"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "class Trainer():\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self.args = kwargs['args']\n",
        "        self.model = kwargs['model'].to(self.args.device)\n",
        "        self.optimizer = kwargs['optimizer']\n",
        "        self.scheduler = kwargs['scheduler']\n",
        "        self.criterion = torch.nn.CrossEntropyLoss().to(self.args.device)\n",
        "        self.losses = []\n",
        "\n",
        "    def loss(self, features):\n",
        "        # Les caractéristiques d'entrée sont un tenseur de torche avec une forme de (2*batch_size, out_dim)\n",
        "        # Les paires positives sont (features[i] et features[i+batch_size]) pour tout i\n",
        "        \n",
        "        # Les étiquettes sont simplement les indices de la classe pour chaque image\n",
        "        batch_indices = torch.arange(self.args.batch_size).repeat(self.args.n_views)\n",
        "        labels = torch.eq(batch_indices.unsqueeze(0), batch_indices.unsqueeze(1)).float().to(self.args.device)\n",
        "        config\n",
        "        # Normaliser les vecteurs pour avoir une norme de 1\n",
        "        normalized_features = F.normalize(features, dim=1)\n",
        "\n",
        "        # Calculer la matrice de similarité (cosine similarity)\n",
        "        similarity = torch.mm(normalized_features, normalized_features.T)\n",
        "\n",
        "        # Enlever les éléments diagonaux, car ils correspondent à la similarité de l'image avec elle-même\n",
        "        diagonal_mask = torch.eye(labels.size(0), dtype=torch.bool).to(self.args.device)\n",
        "        labels_filtered = labels.masked_select(~diagonal_mask).view(labels.size(0), -1)\n",
        "        similarity_filtered = similarity.masked_select(~diagonal_mask).view(similarity.size(0), -1)\n",
        "\n",
        "        # Sélectionner uniquement les positifs et négatifs sans besoin de reformater comme précédemment\n",
        "        positive_pairs = similarity_filtered[labels_filtered.bool()].view(labels.size(0), -1)\n",
        "        negative_pairs = similarity_filtered[~labels_filtered.bool()].view(labels.size(0), -1)\n",
        "\n",
        "        # Préparer les logits pour le calcul de perte\n",
        "        logits = torch.cat([positive_pairs, negative_pairs], dim=1) / self.args.temperature\n",
        "        zero_labels = torch.zeros(logits.size(0), dtype=torch.long).to(self.args.device)\n",
        "        \n",
        "        return self.criterion(logits, zero_labels)\n",
        "\n",
        "    def train(self, dataloader):\n",
        "        # Implement GradScaler if AMP\n",
        "        best_loss = 1e4\n",
        "        scaler = GradScaler(enabled=self.args.fp16_precision)\n",
        "        for epoch in range(self.args.epochs):\n",
        "            for images, _ in tqdm(dataloader):\n",
        "                images = torch.cat(images, dim=0)\n",
        "                images = images.to(self.args.device)\n",
        "\n",
        "                with autocast(enabled=self.args.fp16_precision):\n",
        "                    features = self.model(images)\n",
        "                    loss = self.loss(features)\n",
        "                    self.losses.append(loss.item())\n",
        "                    \n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(self.optimizer)\n",
        "                scaler.update()\n",
        "\n",
        "                self.scheduler.step()\n",
        "\n",
        "            # Warmup for the first 10 epochs (échauffement pour les 10 premières époques)\n",
        "            if epoch >= 10:\n",
        "                self.scheduler.step()\n",
        "            if epoch % 10 == 0 and epoch != 0:\n",
        "                self.save_model(self.model, f\"./HW3_Representation/simclr_models/model_{epoch}.pth\")\n",
        "            if loss < best_loss:\n",
        "                best_loss = loss\n",
        "                self.save_model(self.model, f\"./HW3_Representation/simclr_models/best_model.pth\")\n",
        "            print(f\"Epoch {epoch}, Loss {loss.item()}\")\n",
        "        \n",
        "        return self.model, self.losses\n",
        "\n",
        "    def save_model(self, model, path):\n",
        "        torch.save(model.state_dict(), path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrqKVgUeFfM8"
      },
      "source": [
        "# Étape 2 : Entraînez le réseau de base sur la tâche auxiliaire pendant 70 époques et sauvegardez le meilleur modèle que vous avez pour l'évaluation.\n",
        "\n",
        "Vérifiez si la perte d'entraînement diminue avec le temps et essayez de capturer d'autres bogues possibles à l'aide d'outils de journalisation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/32 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 5/32 [00:50<04:25,  9.85s/it]"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "trainer = Trainer(args=args, model=model, optimizer=optimizer, scheduler=lr_scheduler)\n",
        "model, losses = trainer.train(dataloader)\n",
        "\n",
        "# Save the losses list to a file\n",
        "with open('./HW3_Representation/simclr_models/losses.pkl', 'wb') as f:\n",
        "    pickle.dump(losses, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0WWUzP5emQj"
      },
      "source": [
        "# Étape 3 : Évaluation de la tâche en aval : Former un nouveau décodeur MLP basé sur le codeur formé.\n",
        "\n",
        "Ce processus de fine-tuning devrait être bien plus rapide que le précédent. L'exactitude Top-1 attendue devrait être d'environ 57% et l'exactitude Top-5 devrait être autour de 97%. Obtenir ces résultats est normal car la sonde linéaire est juste une couche de projection généralement reconnue comme n'ayant pas de capacité de représentation. Pour atteindre la performance mentionnée dans l'article, nous avons besoin d'un plus grand dataset, de GPU plus puissants et de plus de temps (environ 1000 époques durant la phase de pré-entraînement)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8R2HGu-UemQj"
      },
      "outputs": [],
      "source": [
        "class linear_prob_Trainer:\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self.args = kwargs[\"args\"]\n",
        "        self.model = kwargs[\"model\"].to(self.args.device)\n",
        "        self.optimizer = kwargs[\"optimizer\"]\n",
        "        self.criterion = torch.nn.CrossEntropyLoss().to(self.args.device)\n",
        "        self.train_dataset = datasets.STL10(\n",
        "            \"./data\", split=\"train\", download=True, transform=transforms.ToTensor()\n",
        "        )\n",
        "\n",
        "        self.train_loader = torch.utils.data.DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=self.args.batch_size,\n",
        "            num_workers=1,\n",
        "            drop_last=False,\n",
        "        )\n",
        "\n",
        "        self.test_dataset = datasets.STL10(\n",
        "            \"./data\", split=\"test\", download=True, transform=transforms.ToTensor()\n",
        "        )\n",
        "\n",
        "        self.test_loader = torch.utils.data.DataLoader(\n",
        "            self.test_dataset,\n",
        "            batch_size=self.args.batch_size,\n",
        "            num_workers=1,\n",
        "            drop_last=False,\n",
        "        )\n",
        "\n",
        "    def accuracy(self, output, target, topk=(1,)):\n",
        "        with torch.no_grad():\n",
        "            maxk = max(topk)\n",
        "            batch_size = target.size(0)\n",
        "\n",
        "            _, pred = output.topk(maxk, 1, True, True)\n",
        "            pred = pred.t()\n",
        "            correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "            res = []\n",
        "            for k in topk:\n",
        "                correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "                res.append(correct_k.mul_(100.0 / batch_size))\n",
        "            return res\n",
        "\n",
        "    def train(self, dataloader):\n",
        "        top1_accs = []\n",
        "        top5_accs = []\n",
        "        for epoch in range(100):\n",
        "            top1_train_accuracy = 0\n",
        "            top5_train_accuracy = 0\n",
        "            for images, labels in tqdm(dataloader):\n",
        "                images, labels = images.to(self.args.device), labels.to(\n",
        "                    self.args.device\n",
        "                )\n",
        "                logits = self.model(images)\n",
        "                loss = self.criterion(logits, labels)\n",
        "                \n",
        "                top1 = self.accuracy(logits, labels, topk=(1,))\n",
        "                top1_train_accuracy += top1[0]\n",
        "                \n",
        "                top5 = self.accuracy(logits, labels, topk=(5,))\n",
        "                top5_train_accuracy += top5[0]\n",
        "\n",
        "                top1_accs.append(top1[0])\n",
        "                top5_accs.append(top5[0])\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                print(\n",
        "                    f\"Epoch: {epoch}, Loss: {loss.item()}\",\n",
        "                    \"Top1 Train Accuracy: \",\n",
        "                    top1_train_accuracy.item() / len(dataloader),\n",
        "                    \"Top5 Train Accuracy: \",\n",
        "                    top5_train_accuracy.item() / len(dataloader),\n",
        "                )\n",
        "        return self.model, top1_accs, top5_accs\n",
        "\n",
        "    def test(self, dataloader):\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            top1_test_accuracy = 0\n",
        "            top5_test_accuracy = 0\n",
        "            for images, labels in tqdm(dataloader):\n",
        "                images, labels = images.to(self.args.device), labels.to(\n",
        "                    self.args.device\n",
        "                )\n",
        "                logits = self.model(images)\n",
        "                top1 = self.accuracy(logits, labels, topk=(1,))\n",
        "                top1_test_accuracy += top1[0]\n",
        "                top5 = self.accuracy(logits, labels, topk=(5,))\n",
        "                top5_test_accuracy += top5[0]\n",
        "            top1_acc = top1_test_accuracy.item() / len(dataloader)\n",
        "            top5_acc = top5_test_accuracy.item() / len(dataloader)\n",
        "            print(\"Top1 Test Accuracy: \", top1_acc)\n",
        "            print(\"Top5 Test Accuracy: \", top5_acc)\n",
        "            return top1_acc, top5_acc\n",
        "\n",
        "model = Net()\n",
        "model.load_state_dict(torch.load(\"./HW3_Representation/simclr_models/best_model.pth\"))\n",
        "\n",
        "model.linear_probe()\n",
        "linear_probe_optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
        "linear_prob_trainer = linear_prob_Trainer(args=args, model=model, optimizer=linear_probe_optimizer)\n",
        "model, top1_train, top5_train = linear_prob_trainer.train(linear_prob_trainer.train_loader)\n",
        "top1_test, top5_test = linear_prob_trainer.test(linear_prob_trainer.test_loader)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
