{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J45M5o5XrUrk"
      },
      "source": [
        "# Objectif :\n",
        "\n",
        "Dans ce devoir, vous allez implémenter une classe `DDPM` sur le dataset MNIST en utilisant PyTorch selon les directives. L'objectif est de minimiser la fonction de perte et d'entraîner le modèle pour générer des images MNIST.\n",
        "\n",
        "Les classes `Train` et `UNet` sont déjà implémentées pour vous. Vous devez implémenter la classe `DDPM` (voir les détails ci-dessous). Les images générées par le modèle seront automatiquement affichées conformément à l'implémentation de la classe `Trainer`. Assurez-vous que les images générées sont affichées dans la sortie, cela sera évalué.\n",
        "\n",
        "Note :\n",
        "- **Implémentation de la classe DDPM (20 points).**\n",
        "- **Entraînement du modèle pour générer des images MNIST raisonnables en 20 époques (10 points).**\n",
        "- **Rédigez un rapport décrivant les exemples d'images générées par chaque période (10 points). Veuillez noter que la fonction pour générer l'image est déjà fournie.**\n",
        "\n",
        "---\n",
        "Veuillez NE PAS changer le code fourni, ajoutez uniquement votre propre code où indiqué. Il est recommandé d'**utiliser une session CPU pour déboguer** lorsque le GPU n'est pas nécessaire puisque Colab ne donne que 12 heures d'accès GPU gratuit à la fois. Si vous utilisez toutes les ressources GPU, vous pouvez envisager d'utiliser les ressources GPU de Kaggle. Merci et bonne chance !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtibzCT8XdVU"
      },
      "source": [
        "# Configuration prédéterminée et fonctions données (pas besoin de changer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMJA9jQfXxuG"
      },
      "outputs": [],
      "source": [
        "!pip install labml_nn labml labml_helpers --no-deps\n",
        "import torch\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from labml_nn.diffusion.ddpm.unet import UNet\n",
        "from typing import Tuple, Optional\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from easydict import EasyDict\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "args = {\n",
        "    \"image_channels\": 1,  # Number of channels in the image. 3 for RGB.\n",
        "    \"image_size\": 32,  # Image size\n",
        "    \"n_channels\": 64,  # Number of channels in the initial feature map\n",
        "    \"channel_multipliers\": [\n",
        "        1,\n",
        "        2,\n",
        "        2,\n",
        "        4,\n",
        "    ],  # The list of channel numbers at each resolution.\n",
        "    \"is_attention\": [\n",
        "        False,\n",
        "        False,\n",
        "        False,\n",
        "        True,\n",
        "    ],  # The list of booleans for attention at each resolution\n",
        "    \"n_steps\": 1000,  # Number of time steps T\n",
        "    \"nb_save\": 5,  # Number of images to save\n",
        "    \"batch_size\": 256,  # Batch size\n",
        "    \"n_samples\": 16,  # Number of samples to generate\n",
        "    \"learning_rate\": 2e-5,  # Learning rate\n",
        "    \"epochs\": 20,  # Number of training epochs\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",  # Device\n",
        "    \"fp16_precision\": False\n",
        "}\n",
        "args = EasyDict(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTF2MO6YTw1x"
      },
      "outputs": [],
      "source": [
        "class MNISTDataset(torchvision.datasets.MNIST):\n",
        "    def __init__(self):\n",
        "        transform = torchvision.transforms.Compose(\n",
        "            [\n",
        "                torchvision.transforms.Resize(args.image_size),\n",
        "                torchvision.transforms.ToTensor(),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        super().__init__(\n",
        "            \".\", train=True, download=True, transform=transform\n",
        "        )\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return super().__getitem__(item)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkHN2yGRTw1y"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    def __init__(self, args, DenoiseDiffusion):\n",
        "\n",
        "        self.eps_model = UNet(\n",
        "            image_channels=args.image_channels,\n",
        "            n_channels=args.n_channels,\n",
        "            ch_mults=args.channel_multipliers,\n",
        "            is_attn=args.is_attention,\n",
        "        ).to(args.device)\n",
        "\n",
        "        self.diffusion = DenoiseDiffusion(\n",
        "            eps_model=self.eps_model,\n",
        "            n_steps=args.n_steps,\n",
        "            device=args.device,\n",
        "        )\n",
        "\n",
        "        self.optimizer = torch.optim.Adam(\n",
        "            self.eps_model.parameters(), lr=args.learning_rate\n",
        "        )\n",
        "        self.args = args\n",
        "\n",
        "    def train_a_round(self, dataloader, scaler):\n",
        "        for data in dataloader:\n",
        "            # Move data to device\n",
        "            data = data.to(args.device)\n",
        "\n",
        "            # Calculate the loss\n",
        "            with autocast(enabled=self.args.fp16_precision):\n",
        "                loss = self.diffusion.loss(data)\n",
        "            # Zero gradients\n",
        "            self.optimizer.zero_grad()\n",
        "            # Backward pass\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(self.optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "    def run_in_a_row(self, dataloader):\n",
        "        scaler = GradScaler(enabled=self.args.fp16_precision)\n",
        "        for current_epoch in tqdm(range(self.args.epochs)):\n",
        "            self.current_epoch = current_epoch\n",
        "            self.train_a_round(dataloader, scaler)\n",
        "            self.sample()\n",
        "\n",
        "    def sample(self):\n",
        "        with torch.no_grad():\n",
        "            # $x_T \\sim p(x_T) = \\mathcal{N}(x_T; \\mathbf{0}, \\mathbf{I})$\n",
        "            x = torch.randn(\n",
        "                [\n",
        "                    self.args.n_samples,\n",
        "                    self.args.image_channels,\n",
        "                    self.args.image_size,\n",
        "                    self.args.image_size,\n",
        "                ],\n",
        "                device=self.args.device,\n",
        "            )\n",
        "            if self.args.nb_save is not None:\n",
        "                saving_steps = [self.args[\"n_steps\"] - 1]\n",
        "            # Remove noise for $T$ steps\n",
        "            for t_ in tqdm(range(self.args.n_steps)):\n",
        "                # $t$\n",
        "                t = self.args.n_steps - t_ - 1\n",
        "                # Sample from $\\textcolor{lightgreen}{p_\\theta}(x_{t-1}|x_t)$\n",
        "                x = self.diffusion.p_sample(\n",
        "                    x, x.new_full((self.args.n_samples,), t, dtype=torch.long)\n",
        "                )\n",
        "                if self.args.nb_save is not None and t_ in saving_steps:\n",
        "                    print(f\"Showing/saving samples from epoch {self.current_epoch}\")\n",
        "                    show_save(\n",
        "                        x,\n",
        "                        show=True,\n",
        "                        save=True,\n",
        "                        file_name=f\"./ddpm_plots/epoch_{self.current_epoch}_sample_{t_}.png\",\n",
        "                    )\n",
        "        return x\n",
        "\n",
        "\n",
        "def show_save(img_tensor, show=True, save=True, file_name=\"sample.png\"):\n",
        "    fig, axs = plt.subplots(3, 3, figsize=(10, 10))  # Create a 4x4 grid of subplots\n",
        "    assert img_tensor.shape[0] >= 9, \"Number of images should be at least 9\"\n",
        "    img_tensor = img_tensor[:9]\n",
        "    for i, ax in enumerate(axs.flat):\n",
        "        # Remove the channel dimension and convert to numpy\n",
        "        img = img_tensor[i].squeeze().cpu().numpy()\n",
        "\n",
        "        ax.imshow(img, cmap=\"gray\")  # Display the image in grayscale\n",
        "        ax.axis(\"off\")  # Hide the axis\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if save:\n",
        "        plt.savefig(file_name)\n",
        "    if show:\n",
        "        plt.show()\n",
        "    plt.close(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW9Mu-QFXjcO"
      },
      "source": [
        "# Terminer l'implémentation du modèle DenoiseDiffusion\n",
        "\n",
        "Selon ce qui a été couvert dans le cours ([diapositives](https://www.dropbox.com/s/0gu91rovro71q90/Diffusion.pdf?dl=0)),\n",
        "\n",
        "Le `Trainer`, le `dataset` et le `UNet` sont donnés.\n",
        "\n",
        "Nous initialisons ${\\epsilon_\\theta}(x_t, t)$, $\\beta_1, \\dots, \\beta_T$ (programme de variance augmentant linéairement), $\\alpha_t = 1 - \\beta_t$, $\\bar\\alpha_t = \\prod_{s=1}^t \\alpha_s$, $\\sigma^2 = \\beta$\n",
        "```python\n",
        "class DenoiseDiffusion:\n",
        "    def __init__(self, eps_model: nn.Module, n_steps: int, device: torch.device):\n",
        "        super().__init__()\n",
        "        self.eps_model = eps_model\n",
        "        self.beta = torch.linspace(0.0001, 0.02, n_steps).to(device)\n",
        "        self.alpha = 1.0 - self.beta\n",
        "        self.alpha_bar = torch.cumprod(self.alpha, dim=0)\n",
        "        self.n_steps = n_steps\n",
        "        self.sigma2 = self.beta\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ehJ22S6ZOTd"
      },
      "source": [
        "## q_xt_x0\n",
        "Nous devons implémenter la fonction :\n",
        "```python\n",
        "    def q_xt_x0(\n",
        "        self, x0: torch.Tensor, t: torch.Tensor\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        ...\n",
        "        return mean, var\n",
        "```\n",
        "$$\n",
        "\\begin{align}\n",
        "q(x_t|x_0) &= \\mathcal{N} \\Big(x_t; \\sqrt{\\bar\\alpha_t} x_0, (1-\\bar\\alpha_t) \\mathbf{I} \\Big)\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Conseil : utilisez la fonction gather donnée. En savoir plus sur `gather()` [ici](https://pytorch.org/docs/stable/generated/torch.gather.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7pBRL-GZza-"
      },
      "source": [
        "## q_sample\n",
        "\n",
        "Nous devons implémenter la fonction pour obtenir des échantillons de $q(x_t|x_0)$.\n",
        "\n",
        "\\begin{align}\n",
        "q(x_t|x_0) &= \\mathcal{N} \\Big(x_t; \\sqrt{\\bar\\alpha_t} x_0, (1-\\bar\\alpha_t) \\mathbf{I} \\Big)\n",
        "\\end{align}\n",
        "\n",
        "Indice : l'échantillonnage à partir de $\\mathcal{N} \\Big(\\mu, \\sigma^2\\Big)$ est identique à l'échantillonnage à partir de $\\mathcal{N} \\Big(0, I\\Big)$, puis mettre à l'échelle et décaler."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kdb8-T3Ea0i8"
      },
      "source": [
        "## p_sample\n",
        "Nous devons implémenter la fonction pour obtenir des échantillons de ${p_\\theta}(x_{t-1}|x_t)$\n",
        "\n",
        "\\begin{align}\n",
        "{p_\\theta}(x_{t-1} | x_t) &= \\mathcal{N}\\big(x_{t-1};\n",
        "{\\mu_\\theta}(x_t, t), \\sigma_t^2 \\mathbf{I} \\big) \\\\\n",
        "{\\mu_\\theta}(x_t, t)\n",
        "  &= \\frac{1}{\\sqrt{\\alpha_t}} \\Big(x_t -\n",
        "    \\frac{\\beta_t}{\\sqrt{1-\\bar\\alpha_t}}{\\epsilon_\\theta}(x_t, t) \\Big)\n",
        "\\end{align}\n",
        "\n",
        "* `beta` est défini comme $1-\\alpha_t$  \n",
        "* `eps_coef` est défini comme $\\frac{\\beta}{\\sqrt{1-\\bar\\alpha_t}}$ * `mu_theta` est défini comme $\\frac{1}{\\sqrt{\\alpha_t}}$\n",
        "* `mu_theta` est défini comme $\\frac{1}{\\sqrt{\\alpha_t}} \\Big(x_t -\\frac{\\beta_t}{\\sqrt{1-\\bar\\alpha_t}}\\epsilon_\\theta(x_t, t) \\Big)$\n",
        "* `var` est défini comme $\\sigma_t^2 \\mathbf{I}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DlpUzpcgJdt"
      },
      "source": [
        "## loss\n",
        "Nous devons implémenter la fonction pour obtenir la perte :\n",
        "$$L(\\theta) = \\mathbb{E}_{t,x_0, \\epsilon} \\Bigg[ \\bigg\\Vert\n",
        "\\epsilon - {\\epsilon_\\theta}(\\sqrt{\\bar\\alpha_t} x_0 + \\sqrt{1-\\bar\\alpha_t}\\epsilon, t)\n",
        "\\bigg\\Vert^2 \\Bigg]$$\n",
        "\n",
        "où `x_t` est échantillonné à partir de $q(x_t|x_0)$ qui est donné par $\\sqrt{\\bar\\alpha_t} x_0 + \\sqrt{1-\\bar\\alpha_t}\\epsilon$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1mAVxIsTw1y"
      },
      "outputs": [],
      "source": [
        "class DenoiseDiffusion:\n",
        "    def __init__(self, eps_model: nn.Module, n_steps: int, device: torch.device):\n",
        "        super().__init__()\n",
        "        self.eps_model = eps_model\n",
        "        self.beta = torch.linspace(0.0001, 0.02, n_steps).to(device)\n",
        "        self.alpha = 1.0 - self.beta\n",
        "        self.alpha_bar = torch.cumprod(self.alpha, dim=0)\n",
        "        self.n_steps = n_steps\n",
        "        self.sigma2 = self.beta\n",
        "\n",
        "    def gather(self, c: torch.Tensor, t: torch.Tensor):\n",
        "        c_ = c.gather(-1, t)\n",
        "        return c_.reshape(-1, 1, 1, 1)\n",
        "\n",
        "    def q_xt_x0(\n",
        "        self, x0: torch.Tensor, t: torch.Tensor\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        mean = torch.sqrt(self.gather(self.alpha_bar, t)) * x0\n",
        "        var = 1 - self.gather(self.alpha_bar, t)\n",
        "        return mean, var\n",
        "\n",
        "    def q_sample(\n",
        "        self, x0: torch.Tensor, t: torch.Tensor, eps: Optional[torch.Tensor] = None\n",
        "    ):\n",
        "        if eps is None:\n",
        "            eps = torch.randn_like(x0)\n",
        "        mean, var = self.q_xt_x0(x0, t)\n",
        "        return mean + torch.sqrt(var) * eps\n",
        "\n",
        "    def p_sample(self, xt: torch.Tensor, t: torch.Tensor):\n",
        "        eps_theta = self.eps_model(xt, t)\n",
        "        alpha_bar = self.gather(self.alpha_bar, t)\n",
        "        alpha = self.gather(self.alpha, t)\n",
        "        beta = 1 - alpha\n",
        "        eps_coef = beta / torch.sqrt(1 - alpha_bar)\n",
        "        mu_theta = (xt - eps_coef * eps_theta) / torch.sqrt(alpha)\n",
        "        var = self.sigma2 * torch.eye(xt.shape[1])\n",
        "        eps = torch.randn(xt.shape, device=xt.device)\n",
        "        sample = mu_theta + torch.sqrt(self.gather(self.sigma2, t)) * eps\n",
        "        return sample\n",
        "\n",
        "    def loss(self, x0: torch.Tensor, noise: Optional[torch.Tensor] = None):\n",
        "        batch_size = x0.shape[0]\n",
        "        t = torch.randint(\n",
        "            0, self.n_steps, (batch_size,), device=x0.device, dtype=torch.long\n",
        "        )\n",
        "        if noise is None:\n",
        "            noise = torch.randn_like(x0)\n",
        "        xt = self.q_sample(x0, t, eps=noise)\n",
        "        eps_theta = self.eps_model(xt, t)\n",
        "        loss = F.mse_loss(noise, eps_theta)\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z59rxXJal-hX"
      },
      "source": [
        "# Commencez l'entraînement une fois que vous avez fini de remplir le code ci-dessus\n",
        "Temps estimé : Environ `400s` pour chaque époque (`20 époques` au total), si vous ne changez pas les paramètres de configuration. Aucune logique de sauvegarde des points de contrôle du modèle n'est implémentée. N'hésitez pas à l'implémenter si vous en avez besoin. Il y aura des échantillons affichés et sauvegardés (en images `.png`) pendant l'entraînement pour chaque époque. Vous devriez pouvoir trouver les images sauvegardées dans les `Fichiers` sur le côté gauche si vous utilisez Google Colab.\n",
        "\n",
        "Remarque : `20 époques` au total est juste un paramètre sûr pour générer des images de style MNIST. Normalement, cela devrait commencer à générer des images interprétables autour de `8 époques`. Si vous ne voyez pas cela, il peut y avoir quelque chose de mal avec votre implémentation. Veuillez vérifier votre code avant d'essayer d'avoir plus d'époques d'entraînement. Merci !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_Cdm6ZiTw1y"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(args, DenoiseDiffusion)\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    MNISTDataset(),\n",
        "    batch_size=args.batch_size,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        ")\n",
        "trainer.run_in_a_row(dataloader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "VtibzCT8XdVU"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
